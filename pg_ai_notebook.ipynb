{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafd66d5",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Rename compose.yaml.default to compose.yaml and edit it if needed. As it stands, it will launch the vectorizer, the database, and ollama.\n",
    "\n",
    "Execute this to start the containers:\n",
    "```sh\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### By the way, if you wreck your install and need to start over:\n",
    "```sh\n",
    "docker compose down\n",
    "docker volume rm pgai_data\n",
    "docker rm pgai_db_1 pgai_vectorizer-worker_1 pgai_ollama_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e64a24",
   "metadata": {},
   "source": [
    "### Setup your PSQL instance\n",
    "\n",
    "```sh\n",
    "docker compose exec db psql\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Install pgai\n",
    "```sql\n",
    "CREATE EXTENSION IF NOT EXISTS ai CASCADE;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "While you're there, create the database table\n",
    "```sql\n",
    "CREATE TABLE books (\n",
    "    id          TEXT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,\n",
    "    filename    TEXT,\n",
    "    author      TEXT,\n",
    "    title       TEXT NOT NULL,\n",
    "    text        TEXT NOT NULL\n",
    ");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "And, before you quit, create the vectorizer\n",
    "```sql\n",
    "SELECT ai.create_vectorizer(\n",
    "     'texts'::regclass,\n",
    "     destination => 'texts_embeddings',\n",
    "     embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "     chunking => ai.chunking_recursive_character_text_splitter('text')\n",
    ");\n",
    "```\n",
    "\n",
    "*Keep in mind that for other texts, you can customize the chunking and embedding models.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faddfe8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If you've got a spare terminal window, you can tail the vectorizer logs\n",
    "```sh\n",
    "docker compose logs -f vectorizer-worker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35645d",
   "metadata": {},
   "source": [
    "---\n",
    "Let's get our imports out of the way. Run this.\n",
    "\n",
    "In your virtual environment, run the following to install the necessary libraries.\n",
    "```sh\n",
    "python -m pip install numpy ollama langchain_text_splitters python-dotenv pandas psycopg2-binary Jinja2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274aac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "from ollama import Client\n",
    "import time\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cc409da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OLLAMA_HOST=os.environ.get(\"OLLAMA_HOST\")\n",
    "DB_String=os.environ.get(\"DATABASE_CONNECTION_STRING\")\n",
    "\n",
    "def connect_db():\n",
    "    return psycopg2.connect(DB_String)\n",
    "\n",
    "def create_table(tablename):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                        CREATE EXTENSION IF NOT EXISTS ai CASCADE;\n",
    "                        \"\"\")\n",
    "\n",
    "            cursor.execute(f\"\"\"\n",
    "                        CREATE TABLE IF NOT EXISTS {tablename} (\n",
    "                            id          BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,\n",
    "                            filename    TEXT,\n",
    "                            author      TEXT,\n",
    "                            title       TEXT NOT NULL,\n",
    "                            text        TEXT NOT NULL\n",
    "                            )\n",
    "                        \"\"\")\n",
    "\n",
    "            cursor.execute(f\"\"\"\n",
    "                        SELECT count(*) from {tablename}_embeddings;\n",
    "                            \"\"\")\n",
    "            cursor.execute(f\"\"\"\n",
    "                            select count(*) from {tablename}_embeddings_store;\n",
    "                           \"\"\")\n",
    "            if(len(cursor.fetchall()) == 0):\n",
    "                cursor.execute(f\"\"\"\n",
    "                            SELECT ai.create_vectorizer(\n",
    "                                '{tablename}'::regclass,\n",
    "                                    destination => '{tablename}_embeddings',\n",
    "                                    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "                                    chunking => ai.chunking_recursive_character_text_splitter('text', 500, 10, separators => array[E'\\n;', ' '])\n",
    "                                )\n",
    "                            \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a20fb4",
   "metadata": {},
   "source": [
    "Now, load some data into the **texts** table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4d66d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barrie-peterpan\n",
      "god-bible\n",
      "god-world192\n",
      "stoker-dracula\n",
      "shakespeare-a lover's complaint\n",
      "shakespeare-all's well that ends well\n",
      "shakespeare-antony and cleopatra\n",
      "shakespeare-as you like it\n",
      "shakespeare-comedy of errors\n",
      "shakespeare-coriolanus\n",
      "shakespeare-cymbeline\n",
      "shakespeare-hamlet\n",
      "shakespeare-julius caesar\n",
      "shakespeare-king henry iv, part 1\n",
      "shakespeare-king henry iv, part 2\n",
      "shakespeare-king henry v\n",
      "shakespeare-king henry vi, part 1\n",
      "shakespeare-king henry vi, part 2\n",
      "shakespeare-king henry vi, part 3\n",
      "shakespeare-king henry viii\n",
      "shakespeare-king john\n",
      "shakespeare-king lear\n",
      "shakespeare-king richard ii\n",
      "shakespeare-king richard iii\n",
      "shakespeare-love's labour's lost\n",
      "shakespeare-lucrece\n",
      "shakespeare-macbeth\n",
      "shakespeare-measure for measure\n",
      "shakespeare-merchant of venice\n",
      "shakespeare-merry wives of windsor\n",
      "shakespeare-midsummer night's dream\n",
      "shakespeare-much ado about nothing\n",
      "shakespeare-othello\n",
      "shakespeare-pericles, prince of tyre\n",
      "shakespeare-romeo and juliet\n",
      "shakespeare-sonnets\n",
      "shakespeare-taming of the shrew\n",
      "shakespeare-tempest\n",
      "shakespeare-timon of athens\n",
      "shakespeare-titus andronicus\n",
      "shakespeare-troilus and cressida\n",
      "shakespeare-twelfth night\n",
      "shakespeare-two gentlemen of verona\n",
      "shakespeare-various\n",
      "shakespeare-venus and adonis\n",
      "shakespeare-winter's tale\n",
      "startrek-fc\n",
      "startrek-gens\n",
      "startrek-ins\n",
      "startrek-nem\n",
      "startrek-tff\n",
      "startrek-tmp\n",
      "startrek-tsfs\n",
      "startrek-tuc\n",
      "startrek-tvh\n",
      "startrek-twok\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "content_directory = \"texts\"\n",
    "\n",
    "class Text:\n",
    "    def __init__(self, filename):\n",
    "        self.title = re.match(r\".+\\\\(.+)\\.txt$\", filename).group(1)\n",
    "        self.author = re.match(r\".+\\\\(\\w+)\\\\.+.txt\", filename).group(1)\n",
    "        self.filename = f\"{self.author}-{self.title}\"\n",
    "\n",
    "        with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "            file_contents = f.read()\n",
    "            self.contents = re.sub(r'[^\\S\\r\\n]+', \" \", file_contents)\n",
    "        # print(f\"{self.title} by {self.author}\")\n",
    "        # print(self.contents[:30])\n",
    "\n",
    "def load_directory(dirname, filter):\n",
    "    return list(Path(dirname).rglob(filter))\n",
    "\n",
    "# This method has an intentional lazy flaw in that if a record is already in the database, we just leave it alone for now.\n",
    "def add_text_record(_text):\n",
    "    print(_text.filename)\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT filename from texts where filename = %s\", [_text.filename])\n",
    "            if(len(cursor.fetchall()) == 0):\n",
    "                cursor.execute(\"INSERT into texts (filename, author, title, text)\" \\\n",
    "                \"VALUES (%s, %s, %s, %s)\", (_text.filename, _text.author, _text.title, _text.contents))\n",
    "\n",
    "create_table(content_directory)\n",
    "files = load_directory(content_directory, \"*.txt\")\n",
    "\n",
    "# Modify this to limit how many texts to vectorize\n",
    "for file in files:\n",
    "    text = Text(str(file))\n",
    "    # We aren't creating an array of Text objects because it could consume an\n",
    "    # outrageous amount of memory if there are tons of texts.\n",
    "    add_text_record(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8531802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "496\n",
      "496\n",
      "497\n",
      "495\n",
      "---\n",
      "499\n",
      "496\n",
      "496\n",
      "497\n",
      "495\n",
      "---\n",
      "499\n",
      "496\n",
      "496\n",
      "499\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "def gather_appropriate_chunks_by_author(author, prompt, count):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                           SELECT \n",
    "                           chunk,\n",
    "                           embedding <=> ai.ollama_embed('nomic-embed-text', %s) as distance\n",
    "                           FROM texts_embeddings\n",
    "                           WHERE author = %s\n",
    "                           ORDER BY distance\n",
    "                           LIMIT %s;\n",
    "                           \"\"\", (prompt, author, count))\n",
    "            return cursor.fetchall()    \n",
    "\n",
    "def gather_appropriate_chunks_by_title(title, prompt, count):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                           SELECT \n",
    "                           chunk,\n",
    "                           embedding <=> ai.ollama_embed('nomic-embed-text', %s) as distance\n",
    "                           FROM texts_embeddings\n",
    "                           WHERE title = %s\n",
    "                           ORDER BY distance\n",
    "                           LIMIT %s;\n",
    "                           \"\"\", (prompt, title, count))\n",
    "            return cursor.fetchall() \n",
    "\n",
    "def gather_inappropriate_chunks(prompt, count):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                           SELECT \n",
    "                           chunk,\n",
    "                           embedding <=> ai.ollama_embed('nomic-embed-text', %s) as distance\n",
    "                           FROM texts_embeddings\n",
    "                           ORDER BY distance\n",
    "                           LIMIT %s;\n",
    "                           \"\"\", (prompt, count))\n",
    "            return cursor.fetchall() \n",
    "            \n",
    "chunks = gather_appropriate_chunks_by_author('god', 'who is the king?', 5)\n",
    "for chunk in chunks:\n",
    "    print(len(chunk[0]))\n",
    "print(\"---\")\n",
    "\n",
    "chunks = gather_appropriate_chunks_by_title('bible', 'who is the king?', 5)\n",
    "for chunk in chunks:\n",
    "    print(len(chunk[0]))\n",
    "print(\"---\")\n",
    "\n",
    "chunks = gather_inappropriate_chunks('who is the king?', 5)\n",
    "for chunk in chunks:\n",
    "    print(len(chunk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909f4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\n",
    "    host='http://192.168.137.117:11434',\n",
    ")\n",
    "prompt_size=8000\n",
    "chunking_size=500\n",
    "chunk_count = prompt_size // chunking_size\n",
    "embed_model = \"nomic-embed-text\"\n",
    "generate_model = \"gemma3:12b\"\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful reading assistant who answers questions\n",
    "based on snippets of text provided in context. Answer only using the context provided,\n",
    "being as concise as possible. If the answer isn't in the context, simply say so.\n",
    "Context:\n",
    "\"\"\"\n",
    "\n",
    "def generate_response(prompt, most_similar_chunks, model):\n",
    "    # client.pull(generate_model) # You really should pre-pull your models\n",
    "    \n",
    "    # most_similar_chunks = gather_inappropriate_chunks(prompt)\n",
    "    # for item in most_similar_chunks:\n",
    "    #     print(item[0])\n",
    "    # print(\"\\n\\n\\n\")\n",
    "    system_prompt = SYSTEM_PROMPT + \"\\n\".join(item[0] for item in most_similar_chunks)\n",
    "    # print(f\"{system_prompt}\\n\\n\")\n",
    "    \n",
    "    response = client.chat(\n",
    "        model,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        stream = True\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def stream_response(stream):\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00613f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter is the \"Great White Father,\" and he is the one who forbade the boys from looking like him. He leads the island, sets rules, and \"thins\" out the lost boys when they threaten to grow up."
     ]
    }
   ],
   "source": [
    "prompt = \"who is peter and what was his role on the island?\"\n",
    "\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title(\"peterpan\", prompt, 7)\n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b93a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('When last we saw him he was stealing across the\\nisland with one finger to his lips and his dagger at the ready. He had\\nseen the crocodile pass by without noticing anything peculiar about it,\\nbut by and by he remembered that it had not been ticking. At first he\\nthought this eerie, but soon concluded rightly that the clock had run\\ndown.\\n\\nWithout giving a thought to what might be the feelings of a\\nfellow-creature thus abruptly deprived of its closest companion, Peter\\nbegan to consider how he could', 0.31855671688404563)\n",
      "('did not compete. For one thing he despised all mothers except\\nWendy, and for another he was the only boy on the island who could\\nneither write nor spell; not the smallest word. He was above all that\\nsort of thing.\\n\\nBy the way, the questions were all written in the past tense. What was\\nthe colour of Mother’s eyes, and so on. Wendy, you see, had been\\nforgetting, too.\\n\\nAdventures, of course, as we shall see, were of daily occurrence; but\\nabout this time Peter invented, with Wendy’s help, a new', 0.33557225648457256)\n",
      "('a god. \\nIn the same quarters were possessions of the chief man of the island, whose name was Publius; who received us, and lodged us three days courteously. \\nAnd it came to pass, that the father of Publius lay sick of a fever and of a bloody flux: to whom Paul entered in, and prayed, and laid his hands on him, and healed him. \\nSo when this was done, others also, which had diseases in the island, came, and were healed: \\nWho also honoured us with many honours; and when we departed, they laded us', 0.34626958507281647)\n",
      "('their friends. Peter had saved Tiger Lily from a dreadful\\nfate, and now there was nothing she and her braves would not do for\\nhim. All night they sat above, keeping watch over the home under the\\nground and awaiting the big attack by the pirates which obviously could\\nnot be much longer delayed. Even by day they hung about, smoking the\\npipe of peace, and looking almost as if they wanted tit-bits to eat.\\n\\nThey called Peter the Great White Father, prostrating themselves before\\nhim; and he liked', 0.3464067506341443)\n",
      "('use the pluperfect and say wakened, but woke is\\nbetter and was always used by Peter.\\n\\nIn his absence things are usually quiet on the island. The fairies take\\nan hour longer in the morning, the beasts attend to their young, the\\nredskins feed heavily for six days and nights, and when pirates and\\nlost boys meet they merely bite their thumbs at each other. But with\\nthe coming of Peter, who hates lethargy, they are under way again: if\\nyou put your ear to the ground now, you would hear the whole', 0.34708247604148645)\n",
      "('her, was Peter, that neither did he.\\n\\nBut of course he cared very much; and he was so full of wrath against\\ngrown-ups, who, as usual, were spoiling everything, that as soon as he\\ngot inside his tree he breathed intentionally quick short breaths at\\nthe rate of about five to a second. He did this because there is a\\nsaying in the Neverland that, every time you breathe, a grown-up dies;\\nand Peter was killing them off vindictively as fast as possible.\\n\\nThen having given the necessary instructions to', 0.34721856570492793)\n",
      "Peter is referred to as \"the Great White Father\" and people prostrate themselves before him. He is also the only boy on the island who could neither write nor spell. He invented a new game with Wendy’s help and used the pluperfect tense, saying \"wakened,\" but preferred \"woke.\" When he is absent, things are usually quiet on the island."
     ]
    }
   ],
   "source": [
    "prompt = \"who is peter and what was his role on the island?\"\n",
    "\n",
    "most_similar_chunks = gather_inappropriate_chunks(prompt, 6)\n",
    "for chunk in most_similar_chunks:\n",
    "    print(chunk)\n",
    "    \n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bec0d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"priest buy any soul with his money, he shall eat of it, and he that is born in his house: they shall eat of his meat. \\nIf the priest's daughter also be married unto a stranger, she may not eat of an offering of the holy things. \\nBut if the priest's daughter be a widow, or divorced, and have no child, and is returned unto her father's house, as in her youth, she shall eat of her father's meat: but there shall be no stranger eat thereof. \\nAnd if a man eat of the holy thing unwittingly, then he\", 0.34392842957334924)\n",
      "('and the most\\ncunning, as well as the bravest of the sons of the ‘land beyond the\\nforest.’ That mighty brain and that iron resolution went with him to his\\ngrave, and are even now arrayed against us. The Draculas were, says\\nArminius, a great and noble race, though now and again were scions who\\nwere held by their coevals to have had dealings with the Evil One. They\\nlearned his secrets in the Scholomance, amongst the mountains over Lake\\nHermanstadt, where the devil claims the tenth scholar as his', 0.3475794046894193)\n",
      "(\"and the countenance of the children that eat of the portion of the king's meat: and as thou seest, deal with thy servants. \\nSo he consented to them in this matter, and proved them ten days. \\nAnd at the end of ten days their countenances appeared fairer and fatter in flesh than all the children which did eat the portion of the king's meat. \\nThus Melzar took away the portion of their meat, and the wine that they should drink; and gave them pulse. \\nAs for these four children, God gave them\", 0.3502734686207374)\n",
      "('give us his flesh to eat? \\nThen Jesus said unto them, Verily, verily, I say unto you, Except ye eat the flesh of the Son of man, and drink his blood, ye have no life in you. \\nWhoso eateth my flesh, and drinketh my blood, hath eternal life; and I will raise him up at the last day. \\nFor my flesh is meat indeed, and my blood is drink indeed. \\nHe that eateth my flesh, and drinketh my blood, dwelleth in me, and I in him. \\nAs the living Father hath sent me, and I live by the Father: so he that eateth', 0.3533056945608084)\n",
      "('Dracula blood were amongst their leaders, for\\nour spirit would not brook that we were not free. Ah, young sir, the\\nSzekelys--and the Dracula as their heart’s blood, their brains, and\\ntheir swords--can boast a record that mushroom growths like the\\nHapsburgs and the Romanoffs can never reach. The warlike days are over.\\nBlood is too precious a thing in these days of dishonourable peace; and\\nthe glories of the great races are as a tale that is told.”\\n\\nIt was by this time close on morning, and we', 0.35819075322050764)\n",
      "('hungry, and would have eaten: but while they made ready, he fell into a trance, \\nAnd saw heaven opened, and a certain vessel descending upon him, as it had been a great sheet knit at the four corners, and let down to the earth: \\nWherein were all manner of fourfooted beasts of the earth, and wild beasts, and creeping things, and fowls of the air. \\nAnd there came a voice to him, Rise, Peter; kill, and eat. \\nBut Peter said, Not so, Lord; for I have never eaten any thing that is common or unclean.', 0.36244182718863016)\n",
      "('shame of my nation, the shame of Cassova, when the\\nflags of the Wallach and the Magyar went down beneath the Crescent? Who\\nwas it but one of my own race who as Voivode crossed the Danube and beat\\nthe Turk on his own ground? This was a Dracula indeed! Woe was it that\\nhis own unworthy brother, when he had fallen, sold his people to the\\nTurk and brought the shame of slavery on them! Was it not this Dracula,\\nindeed, who inspired that other of his race who in a later age again and\\nagain brought his', 0.36489639652864414)\n",
      "The children that eat of the portion of the king's meat ate Dracula's food."
     ]
    }
   ],
   "source": [
    "prompt = \"who ate Dracula's food??\"\n",
    "\n",
    "most_similar_chunks = gather_inappropriate_chunks(prompt, 7)\n",
    "for chunk in most_similar_chunks:\n",
    "    print(chunk)\n",
    "    \n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a21192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a brilliant and surprisingly complex question! The answer depends on which version of Dracula you're talking about. Here's a breakdown of who has eaten Dracula's food across different versions of the story and related works:\n",
      "\n",
      "**1. Bram Stoker's *Dracula* (1897):**\n",
      "\n",
      "*   **Mina Harker:** In a pivotal scene, Mina is subtly fed a seemingly innocuous meal prepared by Dracula himself. This act is a significant turning point, as it marks the beginning of Dracula's influence over her. The exact contents of the meal aren't specified, but it's strongly implied to contain a form of his blood or essence.\n",
      "*   **Renfield:**  The insane patient at Carfax Abbey, Renfield, is used by Dracula to feed and sustain him. Renfield consumes live animals (birds, rats, cats) and offers them to Dracula as a form of sustenance, believing he's fulfilling a divine imperative.  This is a disturbing element of the story demonstrating Dracula's manipulation.\n",
      "\n",
      "**2.  Adaptations and Sequels:**\n",
      "\n",
      "*   **Universal Monster Movies (Bela Lugosi era):** The movies generally don't dwell on who eats Dracula's food. The focus is on *him* feeding.\n",
      "*   **Bram Stoker's *Dracula* (1979 Film):** Frank Langella's Dracula is portrayed as charming and sensual. The matter of who eats his food is not shown in detail.\n",
      "*   **Wesley Snipes' *Blade* Series:**  This is a more modern take where Dracula's food and influence are sometimes shown to be utilized by various creatures and antagonists, but it's not a central plot point.\n",
      "*   **\"Dracula 2000\":** A modern reimagining where Dracula's blood acts as a sustenance for others, but not in the way \"food\" is traditionally understood.\n",
      "*   **Various sequels and spin-offs:**  Depending on the narrative, other vampires, creatures, or even humans might be depicted as consuming something related to Dracula's power or essence.\n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "*   **It's not about \"Dracula having dinner.\"**  The concept of someone eating Dracula's food usually refers to someone being *fed* or influenced by him, often unknowingly.\n",
      "*   **It's about Dracula's power.**  The act of someone consuming something connected to Dracula is a way of demonstrating his power and influence over others.\n",
      "\n",
      "\n",
      "\n",
      "To help me give you a more precise answer, could you tell me which version of Dracula you're most interested in?---\n",
      "The narrator ate “robber steak” - bits of bacon, onion, and beef, seasoned with red pepper, and strung on sticks."
     ]
    }
   ],
   "source": [
    "prompt = \"who ate Dracula's food??\"\n",
    "\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title(\"dracula\", prompt, 20)\n",
    "# for chunk in most_similar_chunks:\n",
    "#     print(chunk)\n",
    "    \n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))\n",
    "print(\"---\")\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title(\"dracula\", prompt, 14)\n",
    "# for chunk in most_similar_chunks:\n",
    "#     print(chunk)\n",
    "    \n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
