{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafd66d5",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Rename compose.yaml.default to compose.yaml and edit it if needed. As it stands, it will launch the vectorizer, the database, and ollama.\n",
    "\n",
    "Execute this to start the containers:\n",
    "```sh\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "In your virtual environment, run the following to install the necessary libraries.\n",
    "```sh\n",
    "python -m pip install numpy ollama langchain_text_splitters\n",
    "```\n",
    "\n",
    "### By the way, if you wreck your install and need to start over:\n",
    "```sh\n",
    "docker compose down\n",
    "docker volume rm pgai_data\n",
    "docker rm pgai_db_1 pgai_vectorizer-worker_1 pgai_ollama_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e64a24",
   "metadata": {},
   "source": [
    "### Setup your PSQL instance\n",
    "\n",
    "```sh\n",
    "docker compose exec db psql\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Install pgai\n",
    "```sql\n",
    "CREATE EXTENSION IF NOT EXISTS ai CASCADE;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "While you're there, create the database table\n",
    "```sql\n",
    "CREATE TABLE books (\n",
    "    id          TEXT PRIMARY KEY,\n",
    "    filename    TEXT,\n",
    "    author      TEXT,\n",
    "    title       TEXT,\n",
    "    text        TEXT\n",
    ");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "And, before you quit, create the vectorizer\n",
    "```sql\n",
    "SELECT ai.create_vectorizer(\n",
    "     'texts'::regclass,\n",
    "     destination => 'book_embeddings',\n",
    "     embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "     chunking => ai.chunking_recursive_character_text_splitter('text')\n",
    ");\n",
    "```\n",
    "\n",
    "*Keep in mind that for other texts, you can customize the chunking and embedding models.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faddfe8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If you've got a spare terminal window, you can tail the vectorizer logs\n",
    "```sh\n",
    "docker compose logs -f vectorizer-worker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35645d",
   "metadata": {},
   "source": [
    "---\n",
    "Let's get our imports out of the way. Run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274aac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "from numpy.linalg import norm\n",
    "from ollama import Client\n",
    "import time\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
