{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafd66d5",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Rename compose.yaml.default to compose.yaml and edit it if needed. As it stands, it will launch the vectorizer, the database, and ollama.\n",
    "\n",
    "Execute this to start the containers:\n",
    "```sh\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### By the way, if you wreck your install and need to start over:\n",
    "```sh\n",
    "docker compose down\n",
    "docker volume rm pgai_data\n",
    "docker rm pgai_db_1 pgai_vectorizer-worker_1 pgai_ollama_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e64a24",
   "metadata": {},
   "source": [
    "### Setup your PSQL instance\n",
    "\n",
    "```sh\n",
    "docker compose exec db psql\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Install pgai\n",
    "```sql\n",
    "CREATE EXTENSION IF NOT EXISTS ai CASCADE;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "While you're there, create the database table\n",
    "```sql\n",
    "CREATE TABLE books (\n",
    "    id          TEXT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,\n",
    "    filename    TEXT,\n",
    "    author      TEXT,\n",
    "    title       TEXT NOT NULL,\n",
    "    text        TEXT NOT NULL\n",
    ");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "And, before you quit, create the vectorizer\n",
    "```sql\n",
    "SELECT ai.create_vectorizer(\n",
    "     'texts'::regclass,\n",
    "     destination => 'texts_embeddings',\n",
    "     embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "     chunking => ai.chunking_recursive_character_text_splitter('text')\n",
    ");\n",
    "```\n",
    "\n",
    "*Keep in mind that for other texts, you can customize the chunking and embedding models.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faddfe8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If you've got a spare terminal window, you can tail the vectorizer logs\n",
    "```sh\n",
    "docker compose logs -f vectorizer-worker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35645d",
   "metadata": {},
   "source": [
    "---\n",
    "Let's get our imports out of the way. Run this.\n",
    "\n",
    "In your virtual environment, run the following to install the necessary libraries.\n",
    "```sh\n",
    "python -m pip install numpy ollama langchain_text_splitters python-dotenv pandas psycopg2-binary Jinja2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274aac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "from ollama import Client\n",
    "import time\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cc409da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OLLAMA_HOST=os.environ.get(\"OLLAMA_HOST\")\n",
    "DB_String=os.environ.get(\"DATABASE_CONNECTION_STRING\")\n",
    "\n",
    "def connect_db():\n",
    "    return psycopg2.connect(DB_String)\n",
    "\n",
    "def create_table(tablename):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                        CREATE EXTENSION IF NOT EXISTS ai CASCADE;\n",
    "                        \"\"\")\n",
    "\n",
    "            cursor.execute(f\"\"\"\n",
    "                        CREATE TABLE IF NOT EXISTS {tablename} (\n",
    "                            id          BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,\n",
    "                            filename    TEXT,\n",
    "                            author      TEXT,\n",
    "                            title       TEXT NOT NULL,\n",
    "                            text        TEXT NOT NULL\n",
    "                            )\n",
    "                        \"\"\")\n",
    "\n",
    "            cursor.execute(f\"\"\"\n",
    "                        SELECT count(*) from {tablename}_embeddings;\n",
    "                            \"\"\")\n",
    "            cursor.execute(f\"\"\"\n",
    "                            select count(*) from {tablename}_embeddings_store;\n",
    "                           \"\"\")\n",
    "            if(len(cursor.fetchall()) == 0):\n",
    "                cursor.execute(f\"\"\"\n",
    "                            SELECT ai.create_vectorizer(\n",
    "                                '{tablename}'::regclass,\n",
    "                                    destination => '{tablename}_embeddings',\n",
    "                                    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "                                    chunking => ai.chunking_recursive_character_text_splitter('text', 500, 10, separators => array[E'\\n;', ' '])\n",
    "                                )\n",
    "                            \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a20fb4",
   "metadata": {},
   "source": [
    "Now, load some data into the **texts** table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d66d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barrie-peterpan\n",
      "god-bible\n",
      "god-world192\n",
      "stoker-dracula\n",
      "shakespeare-a lover's complaint\n",
      "shakespeare-all's well that ends well\n",
      "shakespeare-antony and cleopatra\n",
      "shakespeare-as you like it\n",
      "shakespeare-comedy of errors\n",
      "shakespeare-coriolanus\n",
      "shakespeare-cymbeline\n",
      "shakespeare-hamlet\n",
      "shakespeare-julius caesar\n",
      "shakespeare-king henry iv, part 1\n",
      "shakespeare-king henry iv, part 2\n",
      "shakespeare-king henry v\n",
      "shakespeare-king henry vi, part 1\n",
      "shakespeare-king henry vi, part 2\n",
      "shakespeare-king henry vi, part 3\n",
      "shakespeare-king henry viii\n",
      "shakespeare-king john\n",
      "shakespeare-king lear\n",
      "shakespeare-king richard ii\n",
      "shakespeare-king richard iii\n",
      "shakespeare-love's labour's lost\n",
      "shakespeare-lucrece\n",
      "shakespeare-macbeth\n",
      "shakespeare-measure for measure\n",
      "shakespeare-merchant of venice\n",
      "shakespeare-merry wives of windsor\n",
      "shakespeare-midsummer night's dream\n",
      "shakespeare-much ado about nothing\n",
      "shakespeare-othello\n",
      "shakespeare-pericles, prince of tyre\n",
      "shakespeare-romeo and juliet\n",
      "shakespeare-sonnets\n",
      "shakespeare-taming of the shrew\n",
      "shakespeare-tempest\n",
      "shakespeare-timon of athens\n",
      "shakespeare-titus andronicus\n",
      "shakespeare-troilus and cressida\n",
      "shakespeare-twelfth night\n",
      "shakespeare-two gentlemen of verona\n",
      "shakespeare-various\n",
      "shakespeare-venus and adonis\n",
      "shakespeare-winter's tale\n",
      "startrek-fc\n",
      "startrek-gens\n",
      "startrek-ins\n",
      "startrek-nem\n",
      "startrek-tff\n",
      "startrek-tmp\n",
      "startrek-tsfs\n",
      "startrek-tuc\n",
      "startrek-tvh\n",
      "startrek-twok\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "content_directory = \"texts\"\n",
    "\n",
    "class Text:\n",
    "    def __init__(self, filename):\n",
    "        self.title = re.match(r\".+\\\\(.+)\\.txt$\", filename).group(1)\n",
    "        self.author = re.match(r\".+\\\\(\\w+)\\\\.+.txt\", filename).group(1)\n",
    "        self.filename = f\"{self.author}-{self.title}\"\n",
    "\n",
    "        with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "            file_contents = f.read()\n",
    "            self.contents = re.sub(r'[^\\S\\r\\n]+', \" \", file_contents)\n",
    "        # print(f\"{self.title} by {self.author}\")\n",
    "        # print(self.contents[:30])\n",
    "\n",
    "def load_directory(dirname, filter):\n",
    "    return list(Path(dirname).rglob(filter))\n",
    "\n",
    "# This method has an intentional lazy flaw in that if a record is already in the database, we just leave it alone for now.\n",
    "def add_text_record(_text):\n",
    "    print(_text.filename)\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT filename from texts where filename = %s\", [_text.filename])\n",
    "            if(len(cursor.fetchall()) == 0):\n",
    "                cursor.execute(\"INSERT into texts (filename, author, title, text)\" \\\n",
    "                \"VALUES (%s, %s, %s, %s)\", (_text.filename, _text.author, _text.title, _text.contents))\n",
    "\n",
    "create_table(content_directory)\n",
    "files = load_directory(content_directory, \"*.txt\")\n",
    "\n",
    "# Modify this to limit how many texts to vectorize\n",
    "for file in files:\n",
    "    text = Text(str(file))\n",
    "    # We aren't creating an array of Text objects because it could consume an\n",
    "    # outrageous amount of memory if there are tons of texts.\n",
    "    add_text_record(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8531802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "496\n",
      "496\n",
      "497\n",
      "495\n",
      "---\n",
      "499\n",
      "496\n",
      "496\n",
      "497\n",
      "495\n",
      "---\n",
      "499\n",
      "496\n",
      "496\n",
      "499\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "def gather_appropriate_chunks_by_author_metadata(author, prompt, count):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                           SELECT \n",
    "                           chunk,\n",
    "                           embedding <=> ai.ollama_embed('nomic-embed-text', %s) as distance\n",
    "                           FROM texts_embeddings\n",
    "                           WHERE author = %s\n",
    "                           ORDER BY distance\n",
    "                           LIMIT %s;\n",
    "                           \"\"\", (prompt, author, count))\n",
    "            return cursor.fetchall()    \n",
    "\n",
    "def gather_appropriate_chunks_by_title_metadata(title, prompt, count):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                           SELECT \n",
    "                           chunk,\n",
    "                           embedding <=> ai.ollama_embed('nomic-embed-text', %s) as distance\n",
    "                           FROM texts_embeddings\n",
    "                           WHERE title = %s\n",
    "                           ORDER BY distance\n",
    "                           LIMIT %s;\n",
    "                           \"\"\", (prompt, title, count))\n",
    "            return cursor.fetchall() \n",
    "\n",
    "def gather_inappropriate_chunks(prompt, count):\n",
    "    with connect_db() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                           SELECT \n",
    "                           chunk,\n",
    "                           embedding <=> ai.ollama_embed('nomic-embed-text', %s) as distance\n",
    "                           FROM texts_embeddings\n",
    "                           ORDER BY distance\n",
    "                           LIMIT %s;\n",
    "                           \"\"\", (prompt, count))\n",
    "            return cursor.fetchall() \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "909f4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\n",
    "    host='http://192.168.137.117:11434',\n",
    ")\n",
    "prompt_size=8000\n",
    "chunking_size=500\n",
    "chunk_count = prompt_size // chunking_size\n",
    "embed_model = \"nomic-embed-text\"\n",
    "generate_model = \"gemma3:12b\"\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful reading assistant who answers questions\n",
    "based on snippets of text provided in context. Answer only using the context provided,\n",
    "being as concise as possible. If the answer isn't in the context, simply say so.\n",
    "Context:\n",
    "\"\"\"\n",
    "\n",
    "def generate_response(prompt, most_similar_chunks, model):\n",
    "    # client.pull(generate_model) # You really should pre-pull your models\n",
    "    \n",
    "    # most_similar_chunks = gather_inappropriate_chunks(prompt)\n",
    "    # for item in most_similar_chunks:\n",
    "    #     print(item[0])\n",
    "    # print(\"\\n\\n\\n\")\n",
    "    system_prompt = SYSTEM_PROMPT + \"\\n\".join(item[0] for item in most_similar_chunks)\n",
    "    # print(f\"{system_prompt}\\n\\n\")\n",
    "    \n",
    "    response = client.chat(\n",
    "        model,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        stream = True\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def stream_response(stream):\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00613f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter is described as \"youth, joy,\" and \"a little bird that has broken out of the egg.\" His role on the island includes:\n",
      "\n",
      "*   He is a leader, and his band follows his instructions.\n",
      "*   He is the \"Great White Father\" who is prostrated before.\n",
      "*   He \"thins them out\" amongst the lost boys when they seem to be growing up.\n",
      "*   He leads adventures and saved Tiger Lily from a dreadful fate."
     ]
    }
   ],
   "source": [
    "prompt = \"who is peter and what was his role on the island?\"\n",
    "\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title_metadata(\"peterpan\", prompt, 14) # 14 seems to be the sweetspot. any more and you over-run the context buffer and bad things happen.\n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b93a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('When last we saw him he was stealing across the\\nisland with one finger to his lips and his dagger at the ready. He had\\nseen the crocodile pass by without noticing anything peculiar about it,\\nbut by and by he remembered that it had not been ticking. At first he\\nthought this eerie, but soon concluded rightly that the clock had run\\ndown.\\n\\nWithout giving a thought to what might be the feelings of a\\nfellow-creature thus abruptly deprived of its closest companion, Peter\\nbegan to consider how he could', 0.31855671688404563)\n",
      "('did not compete. For one thing he despised all mothers except\\nWendy, and for another he was the only boy on the island who could\\nneither write nor spell; not the smallest word. He was above all that\\nsort of thing.\\n\\nBy the way, the questions were all written in the past tense. What was\\nthe colour of Mother’s eyes, and so on. Wendy, you see, had been\\nforgetting, too.\\n\\nAdventures, of course, as we shall see, were of daily occurrence; but\\nabout this time Peter invented, with Wendy’s help, a new', 0.33557225648457256)\n",
      "---\n",
      "\n",
      "Peter was the only boy on the island who could neither write nor spell. He invented a new game with Wendy’s help."
     ]
    }
   ],
   "source": [
    "prompt = \"who is peter and what was his role on the island?\"\n",
    "\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title_metadata(\"peterpan\", prompt, 2)\n",
    "for chunk in most_similar_chunks:\n",
    "    print(chunk)\n",
    "print(\"---\\n\")\n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09c5b764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down who Peter is and his incredibly complex role in the TV series *Lost*. **Be warned: This explanation contains MAJOR spoilers.**\n",
      "\n",
      "**Who is Peter?**\n",
      "\n",
      "Peter is the son of John Locke. He's a character who initially appears quite ordinary, almost clumsy and pathetic. He's known for his poor social skills, his reliance on his father, and a general feeling of helplessness. However, as the series progresses, it's revealed that he is *far* from ordinary. He's incredibly powerful, and his true nature is the biggest mystery of the show.\n",
      "\n",
      "**His Role on the Island (and Beyond): A Multi-Layered Explanation**\n",
      "\n",
      "Peter's role is the most convoluted and significant in *Lost*. Here's a breakdown of his functions, progressing from his apparent role on the island to the staggering truth about his identity and purpose:\n",
      "\n",
      "**1. The Protector/Guardian (Initial Appearance):**\n",
      "\n",
      "*   **Obsessed with John:** In the early seasons, Peter's primary concern is his father, John Locke. He's intensely protective of him and tries to cater to his every need, often appearing as a bumbling, insecure figure in John's shadow.\n",
      "*   **Developing Strength:** As the seasons progress, Peter starts developing surprising physical strength and resilience. This is initially presented as a reaction to the island's influence and the need to protect his father.\n",
      "*   **Fighting the \"Others\":** Peter becomes a key figure in defending the survivors against the \"Others\" – the mysterious inhabitants of the island.\n",
      "\n",
      "**2. The Smoke Monster's Connection (The Key Revelation):**\n",
      "\n",
      "*   **The Smoke Monster (Smokey):** This is the big one. It's revealed that Peter is intrinsically linked to the Smoke Monster.  He's not just influenced by it, but *part* of it.  He is essentially the physical manifestation of the Smoke Monster's power.\n",
      "*   **Richard's Explanation:** Richard Alpert, one of the \"Others,\" explains that Smokey is a failsafe – an entity created to protect the island from anyone who would exploit its power or harm it. Peter's father, John, had a destiny intertwined with the island, and Smokey needed a physical form to interact with him and the world.\n",
      "*   **The Move:**  After John's death, Smokey transfers its essence, or \"move\" into Peter, giving him immense strength and abilities.  Peter becomes the Smoke Monster's vessel.\n",
      "\n",
      "**3. The Island's Failsafe & Keeper:**\n",
      "\n",
      "*   **Protecting the Heart of the Island:** Peter’s ultimate role is to protect the heart of the island, a source of unimaginable energy.  The heart needs protection from outside interference, and Peter, as the Smoke Monster's vessel, is that protection.\n",
      "*   **The Move's Purpose:** The Move essentially acts as a guardian, judging those who come to the island and ensuring they don't abuse its power. \n",
      "*   **A Difficult Guardian:** Peter struggles with the responsibility. He's conflicted, wanting to be human and wanting to break free from Smokey's control. He frequently acts impulsively.\n",
      "\n",
      "**4. Beyond the Island: The Source**\n",
      "\n",
      "*   **Not from Earth:** It's eventually revealed that Peter and Smokey aren't from Earth. They originate from another realm, one far older and more powerful than our own.\n",
      "*   **The Source:** The origin of Smokey, and therefore Peter, is revealed to be a being known as “The Source.” The Source is the original wellspring of all energy and life. Smokey's existence is rooted in the Source's power.\n",
      "*   **The Cycle:** Peter's existence is tied to a cyclical pattern: the Source creates a Smoke Monster to guard the island, the Smoke Monster eventually needs a host (Peter), and the cycle repeats.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "*   **Appearance:** Initially a seemingly weak and dependent man.\n",
      "*   **Function:**  Protector of the island, failsafe against exploitation of its power, a physical manifestation of the Smoke Monster.\n",
      "*   **Origin:**  From another realm, a being intrinsically linked to \"The Source.\"\n",
      "*   **Complexity:**  A deeply conflicted character struggling with his identity and the burden of his immense power.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to delve deeper into any specific aspect of Peter's story, like his relationship with his father, his connection to Smokey, or the concept of the Source?"
     ]
    }
   ],
   "source": [
    "prompt = \"who is peter and what was his role on the island?\"\n",
    "\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title_metadata(\"peterpan\", prompt, 17)\n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bec0d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"priest buy any soul with his money, he shall eat of it, and he that is born in his house: they shall eat of his meat. \\nIf the priest's daughter also be married unto a stranger, she may not eat of an offering of the holy things. \\nBut if the priest's daughter be a widow, or divorced, and have no child, and is returned unto her father's house, as in her youth, she shall eat of her father's meat: but there shall be no stranger eat thereof. \\nAnd if a man eat of the holy thing unwittingly, then he\", 0.34392842957334924)\n",
      "('and the most\\ncunning, as well as the bravest of the sons of the ‘land beyond the\\nforest.’ That mighty brain and that iron resolution went with him to his\\ngrave, and are even now arrayed against us. The Draculas were, says\\nArminius, a great and noble race, though now and again were scions who\\nwere held by their coevals to have had dealings with the Evil One. They\\nlearned his secrets in the Scholomance, amongst the mountains over Lake\\nHermanstadt, where the devil claims the tenth scholar as his', 0.3475794046894193)\n",
      "(\"and the countenance of the children that eat of the portion of the king's meat: and as thou seest, deal with thy servants. \\nSo he consented to them in this matter, and proved them ten days. \\nAnd at the end of ten days their countenances appeared fairer and fatter in flesh than all the children which did eat the portion of the king's meat. \\nThus Melzar took away the portion of their meat, and the wine that they should drink; and gave them pulse. \\nAs for these four children, God gave them\", 0.3502734686207374)\n",
      "('give us his flesh to eat? \\nThen Jesus said unto them, Verily, verily, I say unto you, Except ye eat the flesh of the Son of man, and drink his blood, ye have no life in you. \\nWhoso eateth my flesh, and drinketh my blood, hath eternal life; and I will raise him up at the last day. \\nFor my flesh is meat indeed, and my blood is drink indeed. \\nHe that eateth my flesh, and drinketh my blood, dwelleth in me, and I in him. \\nAs the living Father hath sent me, and I live by the Father: so he that eateth', 0.3533056945608084)\n",
      "('Dracula blood were amongst their leaders, for\\nour spirit would not brook that we were not free. Ah, young sir, the\\nSzekelys--and the Dracula as their heart’s blood, their brains, and\\ntheir swords--can boast a record that mushroom growths like the\\nHapsburgs and the Romanoffs can never reach. The warlike days are over.\\nBlood is too precious a thing in these days of dishonourable peace; and\\nthe glories of the great races are as a tale that is told.”\\n\\nIt was by this time close on morning, and we', 0.35819075322050764)\n",
      "('hungry, and would have eaten: but while they made ready, he fell into a trance, \\nAnd saw heaven opened, and a certain vessel descending upon him, as it had been a great sheet knit at the four corners, and let down to the earth: \\nWherein were all manner of fourfooted beasts of the earth, and wild beasts, and creeping things, and fowls of the air. \\nAnd there came a voice to him, Rise, Peter; kill, and eat. \\nBut Peter said, Not so, Lord; for I have never eaten any thing that is common or unclean.', 0.36244182718863016)\n",
      "('shame of my nation, the shame of Cassova, when the\\nflags of the Wallach and the Magyar went down beneath the Crescent? Who\\nwas it but one of my own race who as Voivode crossed the Danube and beat\\nthe Turk on his own ground? This was a Dracula indeed! Woe was it that\\nhis own unworthy brother, when he had fallen, sold his people to the\\nTurk and brought the shame of slavery on them! Was it not this Dracula,\\nindeed, who inspired that other of his race who in a later age again and\\nagain brought his', 0.36489639652864414)\n",
      "---\n",
      "\n",
      "The children that eat of the portion of the king's meat, and the countenance of the children that eat of the portion of the king's meat."
     ]
    }
   ],
   "source": [
    "prompt = \"who ate Dracula's food??\"\n",
    "\n",
    "most_similar_chunks = gather_inappropriate_chunks(prompt, 7)\n",
    "for chunk in most_similar_chunks:\n",
    "    print(chunk)\n",
    "print(\"---\\n\") \n",
    "   \n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a21192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a fun question tied to the recent \"What We Do in the Shadows\" TV series! Here's the breakdown of who ate Dracula's food and why it's such a running gag:\n",
      "\n",
      "**It was Guillermo de la Cruz!**\n",
      "\n",
      "Here's the story:\n",
      "\n",
      "*   **Dracula's Pickiness:** Dracula is incredibly particular about his food. He only eats very specific, rare, and ancient delicacies.\n",
      "*   **Guillermo's Secret Snacking:** Guillermo, Dracula's familiar (who desperately wants to *be* Dracula), would often sneak into the kitchen and eat Dracula's food when he wasn't looking. He did this for a long time, motivated by a mix of hunger and a subconscious desire to connect with his master.\n",
      "*   **The Revelation:**  The running joke escalated when it was revealed (in a hilarious flashback) that Guillermo had been eating Dracula's food for decades! This was a major betrayal in Dracula's eyes.\n",
      "*   **The Ongoing Conflict:** Dracula is constantly discovering evidence of Guillermo's food theft, leading to dramatic confrontations and a lot of comedic exasperation from Dracula.\n",
      "\n",
      "\n",
      "\n",
      "It's become a central, beloved element of the show's humor.\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"who ate Dracula's food??\"\n",
    "\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title_metadata(\"dracula\", prompt, 20)\n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae96c21",
   "metadata": {},
   "source": [
    "Let's use a smaller number of chunks so we fit in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The narrator ate Dracula’s food, which was \"robber steak\" - bits of bacon, onion, and beef, seasoned with red pepper, and strung on sticks."
     ]
    }
   ],
   "source": [
    "most_similar_chunks = gather_appropriate_chunks_by_title_metadata(\"dracula\", prompt, 15) \n",
    "stream_response(generate_response(prompt, most_similar_chunks, generate_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbfc951",
   "metadata": {},
   "source": [
    "Let's use a tiny LLM with the same chunks as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8d9db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jonathan Harker ate Dracula’s food, specifically \"robber steak\"—bits of bacon, onion, and beef seasoned with red pepper, strung on sticks, and roasted over a fire."
     ]
    }
   ],
   "source": [
    "stream_response(generate_response(prompt, most_similar_chunks[:14], \"gemma3:12b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a58db5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“It was my own brother, Jonathan Harker, who ate Draculas’s food. He was consumed by a profound and unsettling restlessness, seeking to understand the nature of the vampire. He was compelled to taste it, driven by a morbid curiosity and a sense of desperate need for knowledge. He did not willingly eat it, but he did consume it, driven by a compulsion that he couldn’t explain.”"
     ]
    }
   ],
   "source": [
    "stream_response(generate_response(prompt, most_similar_chunks[:10], \"gemma3:1b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43a2da36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text states, \"He eat not as others. Even friend Jonathan, who lived with him for weeks, did never see him to eat, never!\""
     ]
    }
   ],
   "source": [
    "prompt = \"Did Jonathan have anything to drink with the meals that Dracula prepared?\"\n",
    "\n",
    "most_similar_chunks = gather_appropriate_chunks_by_title_metadata(\"dracula\", prompt, 15)\n",
    "stream_response(generate_response(prompt, most_similar_chunks, \"gemma3:12b\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
